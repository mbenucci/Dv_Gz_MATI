{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Trimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the data we will be using metaBEAT, a tool tailored towards reproducible and efficient analyses of metabarcoding data that was developed by Christoph Hahn at University of Hull. The pipeline is still under active development and will likely be extended further in the future. The pipeline is available in a Docker container with all necessary dependencies. The Docker image is building on ReproPhylo.\n",
    "\n",
    "In this notebook we will be looking at C01 DNA sequences amplified from freshwater eDNA water collected from rivers across the UK. These samples are taken from sites with invasive alien species present and form part of 2 seperate experiments: 1 method comparrison (comparing kicknet sampling and eDNA metabarcoding, species specific approaches) to detect key inasive alien species and 2 detection of key invasive alien species downstream of known populations, to investigate transport of DNA in flowing water.\n",
    "\n",
    "The metaBEAT tool is designed as a wrapper around a complete analysis from raw data, performing (optionally) de-multiplexing, quality filtering, clustering along the way, to OTU tables in biom format. It currently supports BLAST, Kraken and phylogenetic placement (pplacer). Further approaches will be included in the future to allow for efficient and standardized comparative assessments of all approaches.\n",
    "\n",
    "metaBEAT offers a large number of options. \n",
    "\n",
    "\n",
    "The first step will be to trim/clean our raw Illumina data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will perform basic processing (read trimming, -merging-, chimera removal) of the eDNA data. Clustering and taxonomic assignment will be performed in a separate notebook.\n",
    "\n",
    "Minimum input for an analysis is a set of query sequences in one or several files (accepted are a number of file formats, e.g. fasta, fastq). These will be run through the pipeline sequentially.\n",
    "Information on the nature and location of the query sequence files must be provided in a separate tab-delimited text file via the -Q flags.\n",
    "\n",
    "Each line in this text file should look as follows: unique sample_ID format file1 file2\n",
    "The required text files can be generated in any text editor. So theoretically, nano could be used in the terminal to construct the text file. For reproducibility and ease, a simple program can be used to generate the required file.\n",
    "\n",
    "In the cell below, it is produced using a simple python script. The script will list all files in the location to which you've downloaded your Illumina data (specified via the 'datadir' variable. It assumes that there is a file ending in _R1_001.fastq for each sample. For each such file, it will extract the sample name from the filename and format the required line for the text file accordingly. The resulting file is called Querymap.txt (specified in the 'to' variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd trimming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls -1 ../demultiplex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!echo \"SampleID\" > ../trimming/Sample_names.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for a in $(ls ../demultiplex/ | grep \"R1\" | cut -d '.' -f 1)\n",
    "do \n",
    "   SampleID=$a\n",
    "   \n",
    "   echo -e \"$SampleID\"\n",
    "done >> ../trimming/Sample_names.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ../trimming/Sample_names.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a text file specifying the samples to be processed including the format and location of the reads.\n",
    "The below command expects the Illumina data to be present in 2 fastq files (forward and reverse reads) per sample in a directory ./raw_reads/. It expects the files to be named 'sampleID-marker', followed by '_R1_001' or '_R2_001' to identify the forward/reverse read file respectively. sampleID must correspond to the first column in the file Sample_accessions.tsv, marker is 'C01'.\n",
    "\n",
    "Read file names, for example:\n",
    "\n",
    "../raw_reads/samplename-C01-miseqinformation_R1_001.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for a in $(cat ../trimming/Sample_names.tsv | grep \"SampleID\" -v)\n",
    "do\n",
    "    R1=$(ls -1 ../demultiplex/$a* | grep \".R1\")\n",
    "    R2=$(ls -1  ../demultiplex/$a* | grep \".R2\")\n",
    "\n",
    "    echo -e \"$a\\tfastq\\t$R1\\t$R2\"\n",
    "done > Querymap.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head Querymap.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head Querymap_global.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Raw read processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, perform basic quality trimming and clipping (Trimmomatic) and paired-end read merging (flash). metaBEAT will be used to process all 192 samples in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!metaBEAT_global.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amplicon is expected to be 313 bp long. With a readlength of 300 bp we don't expect to see any primer sequences, so it's not necessary to provide the primer sequence for the trimming algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command to trim, remove adapter sequences and merge reads using the metaBEAT pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "metaBEAT_global.py \\\n",
    "-Q Querymap_global.txt \\\n",
    "--trim_qual 30 \\\n",
    "--merge --forward_only --product_length 313 \\\n",
    "-@ M.Benucci@2015.hull.ac.uk \\\n",
    "-n 5 -v &> log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tail -n 100 log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read processing will take several hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Visualise query survival after trimming\n",
    "\n",
    "metaBEAT will generate a directory with all temporary files that were created during the processing for each sample and will record useful stats summarizing the data processing in the file metaBEAT_read_stats.csv. Should look roughly like this.\n",
    "\n",
    "Can explore the table manually or quickly plot out some of these stats here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('metaBEAT_read_stats.csv',index_col=0)\n",
    "df['fraction'] = df['queries']/(df['total']*0.5)\n",
    "df.fraction.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in the processing will be global clustering of the centroids from all clusters from all samples to produce denovo OTUs. The temporary files from the global clustering and the final OTU table were written to the directory GLOBAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls GLOBAL/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denovo OTU table (numbers are reads) can be briefly to see how OTUs are distributed across your samples.\n",
    "Detailed information on what metaBEAT did to each sample is contained in the log file log. It contains the exact commands that were run for each sample during each step of the process.\n",
    "\n",
    "It's a large text file - look at the first 100 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chimera detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some stats on the read counts before/after trimming, merging etc. are summarized for you in read_stats.csv.\n",
    "\n",
    "Next stage of the processing is chimera detection and removal of putative chimeric sequences. We'll do that using uchime as implemented in vsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir chimera_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd chimera_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load file in fasta format to be used in chimera detection.\n",
    "\n",
    "Prepare Refmap file, i.e. text file that specifies the location and the format of the reference to be used.\n",
    "The reference sequences for freshwater macroinvertebrates are provided in a fasta file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls ../../reference_database/CO1_refdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!echo '../ecoPCR_Invert_DB.fasta\\tfasta\\n' > REFmap.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#Write REFmap\n",
    "for file in $(ls ../../reference_database/CO1_refdb/* | grep \"_SATIVA_cleaned.gb$\")\n",
    "do\n",
    "    echo -e \"$file\\tgb\"\n",
    "done > REFmap.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head REFmap.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!metaBEAT_global.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "metaBEAT_global.py \\\n",
    "-R REFmap.txt \\\n",
    "-f \\\n",
    "-@ M.Benucci@2015.hull.ac.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head refs.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run chimera detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "for a in $(cut -f 1 ../trimming/Querymap_global.txt)\n",
    "do\n",
    "    if [ -s ../trimming/$a/$a\\_trimmed.fasta ]\n",
    "    then\n",
    "        echo -e \"\\n### Detecting chimeras in $a ###\\n\"\n",
    "        mkdir $a\n",
    "        cd $a\n",
    "        vsearch --uchime_ref ../../trimming/$a/$a\\_trimmed.fasta --db ../refs.fasta \\\n",
    "        --nonchimeras $a-nonchimeras.fasta --chimeras $a-chimeras.fasta &> log \n",
    "        cd ..\n",
    "\n",
    "    else\n",
    "        echo -e \"$a is empty\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tail Dv1_gut12_1/log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
